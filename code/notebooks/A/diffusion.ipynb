{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.utils import save_image\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pmldiku\n",
    "from pmldiku import data, model_utils, diffusion, diffusion_utils\n",
    "\n",
    "# extras\n",
    "# import einops\n",
    "# import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# needs to be refactored to src/data -> have to work with abstraction\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport pmldiku.data, pmldiku.diffusion, pmldiku.diffusion_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "cuda = True\n",
    "batch_size = 128\n",
    "epochs = 4\n",
    "device_name = \"cuda\" if cuda else \"cpu\"\n",
    "\n",
    "device = torch.device(device_name)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': device} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: (x - 0.5) * 2)]\n",
    ")\n",
    "\n",
    "loader = data.load_mnist(train=True, trans=transform).setup_data_loader(batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see single image\n",
    "plt.imshow(next(iter(loader))[0][0].squeeze().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title=\"\"):\n",
    "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
    "\n",
    "    # Converting images to CPU numpy arrays\n",
    "    if type(images) is torch.Tensor:\n",
    "        images = images.detach().cpu().numpy()\n",
    "\n",
    "    # Defining number of rows and columns\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images) ** (1 / 2))\n",
    "    cols = round(len(images) / rows)\n",
    "\n",
    "    # Populating figure with sub-plots\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows, cols, idx + 1)\n",
    "\n",
    "            if idx < len(images):\n",
    "                plt.imshow(images[idx][0], cmap=\"gray\")\n",
    "                idx += 1\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    # Showing the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model from params\n",
    "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02  # Originally used by the authors\n",
    "config = diffusion.ParamConfig(n_steps, min_beta, max_beta)\n",
    "model = diffusion.LightningDiffusion(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name             | Type            | Params\n",
      "-----------------------------------------------------\n",
      "0 | diffusion_params | DiffusionParams | 0     \n",
      "1 | network          | MyUNet          | 606 K \n",
      "2 | diffusion        | Diffusion       | 606 K \n",
      "-----------------------------------------------------\n",
      "506 K     Trainable params\n",
      "100 K     Non-trainable params\n",
      "606 K     Total params\n",
      "2.427     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db083c0aead84c8d97f544b044f3e39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting diffusion params to: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "source": [
    "# from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "# callbacks = [TQDMProgressBar()]\n",
    "trainer = pl.Trainer(max_epochs=epochs, devices=1, accelerator=device_name)\n",
    "trainer.fit(model=model, train_dataloaders=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_new_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/fjr906/projects/pml/pmldiku-exam-paper/code/src/pmldiku/diffusion_utils.py:58\u001b[0m, in \u001b[0;36mgenerate_new_images\u001b[0;34m(model, n_samples, device, c, h, w)\u001b[0m\n\u001b[1;32m     56\u001b[0m time_tensor \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mones(n_samples, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m t)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_tensor\u001b[38;5;241m.\u001b[39mdevice, x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 58\u001b[0m eta_theta \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdiffusion_params\u001b[38;5;241m.\u001b[39malphas[t]\n\u001b[1;32m     60\u001b[0m alpha_t_bar \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdiffusion_params\u001b[38;5;241m.\u001b[39malpha_bars[t]\n",
      "File \u001b[0;32m/scratch/fjr906/projects/pml/pmldiku-exam-paper/code/src/pmldiku/diffusion.py:216\u001b[0m, in \u001b[0;36mDiffusion.backward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Run each image through the network for each timestep t in the vector t.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# The network returns its estimation of the noise that was added.\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/fjr906/miniconda3/envs/pml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/fjr906/projects/pml/pmldiku-exam-paper/code/src/pmldiku/diffusion.py:131\u001b[0m, in \u001b[0;36mMyUNet.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# x is (N, 2, 28, 28) (image with positional embedding stacked on channel dimension)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m    133\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mte1(t)\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (N, 10, 28, 28)\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/fjr906/miniconda3/envs/pml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/fjr906/miniconda3/envs/pml/lib/python3.10/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/fjr906/miniconda3/envs/pml/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "generated = diffusion_utils.generate_new_images(\n",
    "        model,\n",
    "        n_samples=100,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_utils.show_images(generated, \"Final result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d480347955cf392d672f0f6b31d078b783190204d100b72812c20a03aac5f89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
